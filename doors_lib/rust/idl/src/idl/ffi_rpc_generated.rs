// automatically generated by the FlatBuffers compiler, do not modify

// @generated

use core::{cmp::Ordering, mem};

extern crate flatbuffers;
use self::flatbuffers::{EndianScalar, Follow};

#[allow(unused_imports, dead_code)]
pub mod ffi_rpc {

    use core::{cmp::Ordering, mem};

    extern crate flatbuffers;
    use self::flatbuffers::{EndianScalar, Follow};

    // struct FfiRpcHeader, aligned to 8
    #[repr(transparent)]
    #[derive(Clone, Copy, PartialEq)]
    pub struct FfiRpcHeader(pub [u8; 16]);
    impl Default for FfiRpcHeader {
        fn default() -> Self {
            Self([0; 16])
        }
    }
    impl core::fmt::Debug for FfiRpcHeader {
        fn fmt(&self, f: &mut core::fmt::Formatter) -> core::fmt::Result {
            f.debug_struct("FfiRpcHeader")
                .field("header_type", &self.header_type())
                .field("rpc_type", &self.rpc_type())
                .field("len", &self.len())
                .finish()
        }
    }

    impl flatbuffers::SimpleToVerifyInSlice for FfiRpcHeader {}
    impl<'a> flatbuffers::Follow<'a> for FfiRpcHeader {
        type Inner = &'a FfiRpcHeader;
        #[inline]
        unsafe fn follow(buf: &'a [u8], loc: usize) -> Self::Inner {
            <&'a FfiRpcHeader>::follow(buf, loc)
        }
    }
    impl<'a> flatbuffers::Follow<'a> for &'a FfiRpcHeader {
        type Inner = &'a FfiRpcHeader;
        #[inline]
        unsafe fn follow(buf: &'a [u8], loc: usize) -> Self::Inner {
            flatbuffers::follow_cast_ref::<FfiRpcHeader>(buf, loc)
        }
    }
    impl<'b> flatbuffers::Push for FfiRpcHeader {
        type Output = FfiRpcHeader;
        #[inline]
        unsafe fn push(&self, dst: &mut [u8], _written_len: usize) {
            let src = ::core::slice::from_raw_parts(self as *const FfiRpcHeader as *const u8, <Self as flatbuffers::Push>::size());
            dst.copy_from_slice(src);
        }
        #[inline]
        fn alignment() -> flatbuffers::PushAlignment {
            flatbuffers::PushAlignment::new(8)
        }
    }

    impl<'a> flatbuffers::Verifiable for FfiRpcHeader {
        #[inline]
        fn run_verifier(v: &mut flatbuffers::Verifier, pos: usize) -> Result<(), flatbuffers::InvalidFlatbuffer> {
            use self::flatbuffers::Verifiable;
            v.in_buffer::<Self>(pos)
        }
    }

    impl<'a> FfiRpcHeader {
        #[allow(clippy::too_many_arguments)]
        pub fn new(header_type: u32, rpc_type: u32, len: u64) -> Self {
            let mut s = Self([0; 16]);
            s.set_header_type(header_type);
            s.set_rpc_type(rpc_type);
            s.set_len(len);
            s
        }

        pub fn header_type(&self) -> u32 {
            let mut mem = core::mem::MaybeUninit::<<u32 as EndianScalar>::Scalar>::uninit();
            // Safety:
            // Created from a valid Table for this object
            // Which contains a valid value in this slot
            EndianScalar::from_little_endian(unsafe {
                core::ptr::copy_nonoverlapping(
                    self.0[0..].as_ptr(),
                    mem.as_mut_ptr() as *mut u8,
                    core::mem::size_of::<<u32 as EndianScalar>::Scalar>(),
                );
                mem.assume_init()
            })
        }

        pub fn set_header_type(&mut self, x: u32) {
            let x_le = x.to_little_endian();
            // Safety:
            // Created from a valid Table for this object
            // Which contains a valid value in this slot
            unsafe {
                core::ptr::copy_nonoverlapping(
                    &x_le as *const _ as *const u8,
                    self.0[0..].as_mut_ptr(),
                    core::mem::size_of::<<u32 as EndianScalar>::Scalar>(),
                );
            }
        }

        pub fn rpc_type(&self) -> u32 {
            let mut mem = core::mem::MaybeUninit::<<u32 as EndianScalar>::Scalar>::uninit();
            // Safety:
            // Created from a valid Table for this object
            // Which contains a valid value in this slot
            EndianScalar::from_little_endian(unsafe {
                core::ptr::copy_nonoverlapping(
                    self.0[4..].as_ptr(),
                    mem.as_mut_ptr() as *mut u8,
                    core::mem::size_of::<<u32 as EndianScalar>::Scalar>(),
                );
                mem.assume_init()
            })
        }

        pub fn set_rpc_type(&mut self, x: u32) {
            let x_le = x.to_little_endian();
            // Safety:
            // Created from a valid Table for this object
            // Which contains a valid value in this slot
            unsafe {
                core::ptr::copy_nonoverlapping(
                    &x_le as *const _ as *const u8,
                    self.0[4..].as_mut_ptr(),
                    core::mem::size_of::<<u32 as EndianScalar>::Scalar>(),
                );
            }
        }

        pub fn len(&self) -> u64 {
            let mut mem = core::mem::MaybeUninit::<<u64 as EndianScalar>::Scalar>::uninit();
            // Safety:
            // Created from a valid Table for this object
            // Which contains a valid value in this slot
            EndianScalar::from_little_endian(unsafe {
                core::ptr::copy_nonoverlapping(
                    self.0[8..].as_ptr(),
                    mem.as_mut_ptr() as *mut u8,
                    core::mem::size_of::<<u64 as EndianScalar>::Scalar>(),
                );
                mem.assume_init()
            })
        }

        pub fn set_len(&mut self, x: u64) {
            let x_le = x.to_little_endian();
            // Safety:
            // Created from a valid Table for this object
            // Which contains a valid value in this slot
            unsafe {
                core::ptr::copy_nonoverlapping(
                    &x_le as *const _ as *const u8,
                    self.0[8..].as_mut_ptr(),
                    core::mem::size_of::<<u64 as EndianScalar>::Scalar>(),
                );
            }
        }
    }
} // pub mod ffi_rpc
